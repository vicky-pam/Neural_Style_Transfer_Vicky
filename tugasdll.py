# -*- coding: utf-8 -*-
"""tugasDLL

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1r4SaRv1LbD04vLGzzPfaTEl87PwdD1bt
"""

# Neural Style Transfer
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import PIL.Image as Image

# load gambar (content + style)
content_path = "/content/fotobangunan.jpg"
style_path = "/content/gambarabstrak.jpg"

def load_img(p):
    img = Image.open(p)
    img = img.resize((512, 512))
    img = np.array(img, dtype=np.float32)
    img = np.expand_dims(img, 0)
    return img

content_image = load_img(content_path)
style_image = load_img(style_path)

#print
plt.figure(figsize=(8,4))
plt.subplot(1,2,1)
plt.title("Content")
plt.imshow(content_image[0]/255)
plt.axis("off")

plt.subplot(1,2,2)
plt.title("Style")
plt.imshow(style_image[0]/255)
plt.axis("off")
plt.show()

# VGG19
vgg = tf.keras.applications.VGG19(include_top=False, weights="imagenet")
vgg.trainable = False

content_layers = ['block5_conv2']
style_layers = [
    'block1_conv1',
    'block2_conv1',
    'block3_conv1',
    'block4_conv1',
    'block5_conv1'
]

model = tf.keras.Model(
    inputs=vgg.input,
    outputs=[vgg.get_layer(n).output for n in (style_layers + content_layers)]
)

#gram matrix
def gram_matrix(x):
    x = tf.reshape(x, (-1, x.shape[-1]))
    return tf.matmul(x, x, transpose_a=True) / tf.cast(tf.shape(x)[0], tf.float32)

#fitur dari gambar
def extract(img):
    x = tf.keras.applications.vgg19.preprocess_input(img)
    out = model(x)
    s = out[:len(style_layers)]
    c = out[len(style_layers):]
    g = [gram_matrix(f) for f in s]
    return g, c

style_t, content_t = extract(style_image)

#dioptimasi
generated = tf.Variable(content_image, dtype=tf.float32)

# hyperparam
style_w = 1e-2
content_w = 1e4
opt = tf.optimizers.Adam(5.0)

@tf.function
def step():
    with tf.GradientTape() as t:
        gs, gc = extract(generated)
        sl = tf.add_n([tf.reduce_mean((gs[i] - style_t[i])**2) for i in range(len(style_t))])
        cl = tf.reduce_mean((gc[0] - content_t[0])**2)
        total = style_w * sl + content_w * cl
    grad = t.gradient(total, generated)
    opt.apply_gradients([(grad, generated)])
    generated.assign(tf.clip_by_value(generated, 0, 255))
    return total

# training
epochs = 100
for i in range(epochs):
    loss = step()
    if i % 25 == 0:
        print("step", i, "loss:", loss.numpy())

# hasilnya
plt.figure(figsize=(6,6))
plt.imshow(generated[0]/255)
plt.axis("off")
plt.title("Result")
plt.show()

# simpan
out = Image.fromarray(np.uint8(generated.numpy()[0]))
out.save("/content/output.jpg")
print("saved.")